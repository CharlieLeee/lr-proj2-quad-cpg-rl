{
  "energy_weight": 0.0,
  "lr": 0.0003,
  "policy": "PPO",
  "num_env": 128,
  "timesteps": 1000000,
  "dy_rand": true,
  "jointpd": true
}