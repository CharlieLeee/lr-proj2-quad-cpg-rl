{
  "energy_weight": 0.0,
  "lr": 0.0003,
  "policy": "PPO",
  "num_env": 32,
  "timesteps": 1000000,
  "dy_rand": false
}